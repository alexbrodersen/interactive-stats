[
["index.html", "Psychological and Educational Measurement Lab | Notre Dame 1 Introduction", " Psychological and Educational Measurement Lab | Notre Dame Last Updated: 2019-04-03 1 Introduction Welcome to the Psychological and Educational Measurement Lab at the University of Notre Dame. This is a bookdown document that is intended to be living documentation for all activities that need to be accomplished in our lab. By carefully reading all of this documentation, you will develop a set of valuable skills. Specifically, we hope that you will learn Data Visualization Programming (R, Python, Javascript, SQL) Statistics Psychometrics Data Science Research Design in Psychology Educational Research Methodology Online Data Collection Version Control Intermixed in the documentation and learning materials, you may find quizzes to evaluate your learning. These quizzes are linked to your personal login account and help us know that you have successfully completed a module that is relevent. The more modules you complete, the better you will be able to help out the lab. "],
["exploring-data.html", "2 Exploring Data 2.1 Constructing and interpreting plots 2.2 Summary Statistics 2.3 Exploring bivariate data 2.4 Categorical Data", " 2 Exploring Data Describing patterns and departures from patterns Exploratory analysis of data makes use of graphical and numerical techniques to study patterns and departures from patterns. Emphasis should be placed on interpreting information from graphical and numerical displays and summaries. 2.1 Constructing and interpreting plots Constructing and interpreting graphical displays of distributions of univariate data 2.1.1 Understanding dotplot 2.1.2 Understanding stemplot 2.1.3 Understanding histogram 2.1.4 Understanding cumulative frequency plot 2.1.5 Locating Center from a graph 2.1.6 Locating Spread from a graph 2.1.7 Identifying (a)symmetry of graph 2.1.8 Identifying modality of graph 2.1.9 Identifying a point from a graph using scales and labels 2.2 Summary Statistics Summarizing distributions of univariate data 2.2.1 Calculating median 2.2.2 Calculating mean 2.2.3 Knowing the appropriate context to use median over mean or vice versa 2.2.4 Calculating range 2.2.5 Calculating interquartile range (IQR) 2.2.6 Calculating variance 2.2.7 Calculating standard deviation 2.2.8 Recognizing difference between sample and population standard deviation 2.2.9 Knowing appropriate context to use IQR over standard deviation 2.2.10 Calculating z-score given a raw score, and the mean and sd (from X to z) 2.2.11 Interpret z-scores (number of SDs above/below mean) 2.2.12 Calculating quartiles 2.2.13 Interpreting percentiles 2.2.14 Comparing positions within data (percentile, quantile, standard scores) 2.2.15 Determining effect of changing units on summary statistics 2.2.16 Identifying a correct boxplot 2.2.17 Interpreting values within a boxplot 2.2.18 Calculating outliers using fence 2.2.19 Comparing distributions of data Comparing distributions of univariate data (dotplots back-to-back stemplots parallel boxplots) 2.2.20 Comparing and interpreting centers 2.2.21 Comparing and interpreting spreads 2.2.22 Comparing and interpreting shapes 2.2.23 Comparing and interpreting clusters/gaps 2.2.24 Comparing and interpreting outlier 2.3 Exploring bivariate data Exploring bivariate data 2.3.1 Identifying shape, direction, strength of a Scatterplot 2.3.2 Knowing properties of a Correlation coefficient 2.3.3 Interpreting coefficient of determination: R square 2.3.4 Writing Least Squares Regression Line (LSRL)from computer output 2.3.5 Obtaining LSRL from dataset 2.3.6 Writing LSRL from summary statistics (using b1=r*(sy/sx) formula) (not likely) 2.3.7 Interpreting slope 2.3.8 Interpreting intercept 2.3.9 Finding a predicted y-hat or based on y-hat to find x given the regression equation 2.3.10 Finding a residual value given the regression equation 2.3.11 Interpreting a residual 2.3.12 Using residual plot to determine if transformation is needed, i.e., is linear model appropriate 2.3.13 Understanding lower reliability in extrapolation 2.3.14 Identifying influential points and their impact on model (leverage) 2.3.15 Identifying correct re-expression (log, power, exponential) 2.3.16 Correctly calculating a predicted value under a transformation (log/power/exponential 2.4 Categorical Data Exploring categorical data 2.4.1 Knowing the Difference between categorical and quantitative variables 2.4.2 Calculating Marginal frequencies for two-way tables 2.4.3 Calculating Joint frequencies for two-way tables 2.4.4 Calculating Conditional relative frequencies 2.4.5 Infer Association between categorical variables 2.4.6 Comparing distributions using bar charts with relative frequencies "],
["sampling-and-experimentation.html", "3 Sampling and Experimentation 3.1 Methods of data collection 3.2 Planning and conducting surveys 3.3 Planning and conducting experiments 3.4 Generalizability of results 3.5 Miscellaneous", " 3 Sampling and Experimentation Planning and conducting a study Data must be collected according to a well-developed plan if valid information on a conjecture is to be obtained. This plan includes clarifying the question and deciding upon a method of data collection and analysis. 3.1 Methods of data collection Overview of methods of data collection 3.1.1 Knowing census is a collection of info. from the entire population 3.1.2 Knowing the distinction between experimental and observational stud 3.2 Planning and conducting surveys Planning and conducting surveys 3.2.1 Knowing a well conducted and designed survey must be random 3.2.2 Knowing a well conducted and designed survey must minimize bias 3.2.3 Knowing the population of interest for a sample survey 3.2.4 Distinguishing between population parameter and sample statistics 3.2.5 Identifying a sample was collected randomly (addresses when sample collected with voluntary or convenience) 3.2.6 Understanding what a response and non-response bias is 3.2.7 Identifying when a sample is collected using a simple random sample 3.2.8 Identifying when a sample is collected using stratified random sample 3.2.9 Identifying when a sample is collected using cluster random sample 3.3 Planning and conducting experiments Planning and conducting experiments 3.3.1 Knowing in an experiment that treatments are assigned randomly 3.3.2 Knowing in an experiment that treatments are replicated to many subjects/experimental units 3.3.3 Understanding the benefit for a control group 3.3.4 Identifying # of treatments from a multi-factor experiment (in curriculum?) 3.3.5 Identifying the experimental units in an experiment 3.3.6 Knowing to control variables that are not a factor of an experiment (in curriculum?) 3.3.7 Knowing the purpose of random assignment in experiments 3.3.8 Understanding the difference between none, single and double blinded experiments 3.3.9 Understanding that blinding helps prevent bias in experiment 3.3.10 Understanding the purpose of blocking in an experiment 3.3.11 Identifying between completely randomized and randomized block design 3.3.12 Identifying a matched pairs design 3.4 Generalizability of results Generalizability of results and types of conclusions that can be drawn from observational studies experiments and surveys 3.4.1 Knowing experimental studies can show causation whereas observational studies do not 3.4.2 Knowing experimental results can only be generalized to those represented by the experimental unit 3.5 Miscellaneous Miscellaneous 3.5.1 When to use stratified vs. cluster sampling (homogeneous groups vs heterogeneous group) 3.5.1.1 Random sampling variability 3.5.1.2 Identifying confounding variable "],
["anticipating-patterns.html", "4 Anticipating Patterns 4.1 Probability 4.2 Combining Independent random variables 4.3 Normal Distribution 4.4 Sampling distributions", " 4 Anticipating Patterns Exploring random phenomena using probability and simulation Probability is the tool used for anticipating what the distribution of data should look like under a given model. 4.1 Probability Probability 4.1.1 Interpreting probability as a long-run relative frequency interpretation 4.1.2 Understanding the Law of Large Numbers 4.1.3 Understanding and correctly applying the Addition Rule 4.1.4 Understanding and correctly applying the Multiplication Rule 4.1.5 Calculating conditional probability 4.1.6 Recognizing independent events 4.1.7 Recognizing disjoint (mutually exclusive) events 4.1.8 Distinguishing between discrete and continuous random variables 4.1.9 Recognizing a binomial random variable 4.1.10 Computinga binomial probability 4.1.11 Recognizing a geometric random variable 4.1.12 Computing a geometric probability 4.1.13 Computing cumulative probability of a discrete random variable 4.1.14 Interpreting a simulation of random behavior or a simulated probability distribution 4.1.15 Calculating the mean (expected value) of a discrete random variable 4.1.16 Calculating the standard deviation of a discrete random variable 4.1.17 Understanding the effects of a linear transformation on a random variable (i.e. on the measures of center and spread) 4.1.18 Using common structures to analyze probability problems (Venn diagram, tree, table 4.2 Combining Independent random variables 4.2.1 Distinguishing between independent and dependent events 4.2.2 Calculating the mean for the sum or the difference of independent random variables 4.2.3 Calculating the standard deviation for the sum or the difference of independent random variables 4.3 Normal Distribution 4.3.1 Understanding the characteristics of the normal distribution (symmetric, 68-95-99.7 rule, unimodal, etc.) 4.3.2 Calculating a probability using the z-score and the standard normal distribution (e.g., normcdf) 4.3.3 Calculating a z-score using probabilities on a normal distribution(e.g., norminv) 4.3.4 Calculating the raw-score given a z-score (from z to X) 4.3.5 Using the normal distribution to model and calculate measurements from a contextual application 4.4 Sampling distributions 4.4.1 Interpreting the concept of a sampling distribution 4.4.2 Describing the sampling distribution of a sample proportion (shape, center, spread) 4.4.3 Describing the sampling distribution of a sample mean (shape, center, spread) 4.4.4 Applying the Central Limit Theorem 4.4.5 Describing the sampling distribution of the difference between two independent sample proportions (shape, center, spread) 4.4.6 Describing the sampling distribution of the difference between two independent sample means (shape, center, spread) 4.4.7 Interpreting a simulation of a sampling distribution 4.4.8 Understanding characteristics of a t-distribution 4.4.9 Using the t-distribution to calculate a probability 4.4.10 Using the t-distribution to obtain a t score (critical value) 4.4.11 Understanding the differences between a t-distribution and a normal distribution 4.4.12 Understanding the characteristics of the chi-square distribution 4.4.13 Using the chi-square to calculate probability "],
["statistical-inference.html", "5 Statistical Inference 5.1 Estimation 5.2 Tests of significance", " 5 Statistical Inference Estimating population parameters and testing hypotheses Statistical inference guides the selection of appropriate models. 5.1 Estimation Estimation (point estimators and confidence intervals) 5.1.1 Margins of error vs standard error 5.1.2 Margin of error/interval length, i.e., interaction with sample size and/or level of confidence 5.1.3 Logic of confidence intervals 5.1.4 Interpreting confidence level 5.1.5 Computing Large sample confidence interval for a proportion 5.1.6 Computing Large sample confidence interval for a difference between two proportions 5.1.7 Computing Confidence interval for a mean 5.1.8 Computing Confidence interval for a difference between two means: unpaired 5.1.9 Computing Confidence interval for a difference between two means: paired 5.1.10 Computing Confidence interval for the slope of a least-squares regression line 5.2 Tests of significance Tests of significance 5.2.1 Logic of significance testing, null and alternative hypotheses 5.2.2 Concept of p-values (e.g., using NORMCDF given a critical value) 5.2.3 Interpretation of a p-value (e.g., percentage of times the sample result will occur if the null is true) 5.2.4 Understanding/Comparing one-and two-sided tests 5.2.5 Concepts of Type I error 5.2.6 Concept of Type II errors 5.2.7 Concept of power 5.2.8 Relationship among type-I and type-II errors and power 5.2.9 Effect of changing sample size on type II error, power for fixed level of significance 5.2.10 Conditions for inference for a proportion 5.2.11 Performing Large sample test for a proportion 5.2.12 Conditions for inference for difference in two proportions 5.2.13 Performing Large sample test for a difference between two proportions 5.2.14 Conditions for inference for a mean 5.2.15 Performing Test for a mean 5.2.16 Conditions for inference for a difference between two means 5.2.17 Performing test for a difference between two means: unpaired (t-test) 5.2.18 Performing Test for a difference between two means: paired (t-test) 5.2.19 Conditions for Chi-square test 5.2.20 Performing Chi-square test for goodness of fit 5.2.21 Performing Chi-square test for homogeneity of proportions 5.2.22 Performing Chi-square test for independence (two-way tables) 5.2.23 Performing Test for the slope of a least-squares regression line 5.2.24 Parallel between 2-sided test and confidence interval for the means 5.2.25 Making decision/conclusion by comparing p-value and alpha {r rnorm(10)} I drive a Ford Chevy Dodge to school each day. "]
]
